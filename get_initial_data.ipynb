{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from thefuzz import process,fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data and models folders if they do not exist:\n",
    "import os\n",
    "\n",
    "data_dir = './data'\n",
    "models_dir = './models'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccac17c",
   "metadata": {},
   "source": [
    "# load immunotherapy data and split into train and test cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a80177",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_immunotherapy = pd.read_csv('./data/all_immunotherapy.csv', low_memory=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_immunotherapy.Description_Text=all_immunotherapy.Description_Text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f99554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete\n",
    "all_immunotherapy = all_immunotherapy.dropna(subset=['Description_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients = all_immunotherapy['PatNum'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the  patient into test and train cohorts\n",
    "random.seed(42)\n",
    "test_patients = random.sample(list(all_patients), k=int(len(all_patients) * 0.2))\n",
    "train_patients = [x for x in all_patients if x not in test_patients]\n",
    "pickle.dump((train_patients, test_patients),open('./data/train_test_patients.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=all_immunotherapy.loc[all_immunotherapy.PatNum.isin(train_patients)].copy()\n",
    "test_text=all_immunotherapy.loc[all_immunotherapy.PatNum.isin(test_patients)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14cad0",
   "metadata": {},
   "source": [
    "# Detect all potential IrAE mentiones in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bdbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all words in the database \n",
    "import re,string\n",
    "\n",
    "all_words = set()\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "for row in tqdm(all_immunotherapy.itertuples()):\n",
    "    try:\n",
    "        description_text = regex.sub('', row.Description_Text)\n",
    "    except:\n",
    "        print(row.Description_Text)\n",
    "    all_words.update(description_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed037b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the words in the corpus that are similar to IrAEs in Hebrew and English, providing a high sensitivity \n",
    "# Also allows for mispellings that are common in the EHRs. \n",
    "\n",
    "itis_words={'קוליטיס':'colitis', 'colitis':'colitis','דרמטיטיס':'dermatitis', 'dermatitis':'dermatitis', \n",
    "           'הפטיטיס':'hepatitis','hepatitis':'hepatitis', 'מיאסטניה':'myasthenia','myasthenia':'myasthenia',\n",
    "           'מיוקרדיטיס':'myocarditis','myocarditis':'myocarditis','פנאומוניטיס':'pneumonitis','pneumonitis':'pneumonitis',\n",
    "           'תירואידיטיס':'thyroiditis','thyroiditis':'thyroiditis'}\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "similar_words_dict = defaultdict(list)\n",
    "\n",
    "for key in itis_words.keys():\n",
    "    similar_words = process.extract(key, all_words, limit=500, scorer=fuzz.token_set_ratio)\n",
    "    similar_words_final = [res[0] for res in similar_words if res[1] >= 80]\n",
    "    similar_words_dict[itis_words[key]] += similar_words_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae19ec4",
   "metadata": {},
   "source": [
    "# Extract all lines with IrAEs mentions in the train and test cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc269ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def get_row_for_word(search_words, df,itis_category, n_words=5):\n",
    "    result = []\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        description_text = regex.sub('', row.Description_Text)\n",
    "        description_text_list = description_text.split()\n",
    "        \n",
    "        for i, word in enumerate(description_text_list):\n",
    "            if word in search_words:\n",
    "                start_index = max(0, i - n_words)\n",
    "                end_index = min(i + n_words + 1, len(description_text_list))\n",
    "                X = description_text_list[start_index:end_index]\n",
    "                row_text = \" \".join(X)\n",
    "                row_context = ' '.join(description_text_list[max(0, i - n_words * 2):min(i + n_words * 2 + 1, len(description_text_list))])\n",
    "\n",
    "                result.append([row.PatNum, row.Entry_Date, row.Description_Text, row.Note_id, X, row_text, row_context, itis_category, word])\n",
    "\n",
    "    result = pd.DataFrame(result, columns=['PatNum', 'Entry_Date', 'Description_Text','Note_id','X', 'row_text', 'row_context', 'itis_category','word'])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5bca9d",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_final=pd.concat([get_row_for_word(similar_words_dict[key],train_text,key, n_words=5) for key in tqdm(similar_words_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicates of the imidiate text fot the IrAE for the same patient, keeping the first mention\n",
    "train_data_final=train_data_final.sort_values(by=['PatNum','Entry_Date'], ascending=True)\n",
    "train_data_final=train_data_final.drop_duplicates(subset=['PatNum','row_text'], keep='first').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b804b9",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63656901",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_final=pd.concat([get_row_for_word(similar_words_dict[key],test_text,key, n_words=5) for key in tqdm(similar_words_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicates of the imidiate text fot the IrAE for the same patient, keeping the first mention\n",
    "test_data_final=test_data_final.sort_values(by=['PatNum','Entry_Date'], ascending=True)\n",
    "test_data_final=test_data_final.drop_duplicates(subset=['PatNum','row_text'], keep='first').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8adfc6",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd122bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "train_len = train_data_final.shape[0]\n",
    "test_len = test_data_final.shape[0]\n",
    "all_len = train_len + test_len\n",
    "\n",
    "# create a shuffles index that will be used later to merge back the labeled notes \n",
    "indices = [x for x in range(all_len)]\n",
    "random.shuffle(indices)\n",
    "\n",
    "# As the index is suffled there \n",
    "train_data_final['label_id'] = indices[:train_len]\n",
    "test_data_final['label_id'] = indices[train_len:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ab52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the train and test data for labeling\n",
    "to_label=pd.concat([train_data_final[['row_text', 'row_context','label_id']],test_data_final[['row_text', 'row_context','label_id']]])\n",
    "to_label=to_label.sort_values(by=['label_id'], ascending=True)\n",
    "# The file for labeling\n",
    "to_label.to_csv('./data/data_for_labeling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6573d",
   "metadata": {},
   "source": [
    "# Load labeled data and prepair the final data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43286c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the final labeled data\n",
    "labeled=pd.read_csv('./data/labeled_data.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_final_exported=train_data_final[['PatNum', 'Entry_Date',\n",
    "                                            'Note_id','row_text','X','itis_category', 'label_id','word']].merge(labeled[['label_id','clf']], on=['label_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef700d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_final_exported=test_data_final[['PatNum', 'Entry_Date',\n",
    "                                            'Note_id','row_text','X','itis_category', 'label_id','word']].merge(labeled[['label_id','clf']], on=['label_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final labeled data\n",
    "data_for_model=train_data_final_exported,test_data_final_exported\n",
    "import pickle\n",
    "pickle.dump(data_for_model, open('./data/data_for_model.pickle','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
