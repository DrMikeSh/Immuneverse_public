{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re, string\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe98568",
   "metadata": {},
   "source": [
    "# Medical adaptation of the FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part was conducted using the gensim package implementation:  https://radimrehurek.com/gensim/models/fasttext.html\n",
    "# The pretrained FastText vectors are availible for download at:  https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "# optional code:\n",
    "import urllib.request\n",
    "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.he.300.bin.gz'\n",
    "filename = './models/cc.he.300.bin.gz'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "prev_model = load_facebook_model('./models/cc.he.300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df024313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretraining data\n",
    "pretraining_data= pickle.load(open('./data/pretraining_data.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the words in the pretraining data\n",
    "regex_num = r'\\d'\n",
    "prep_text = []\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "for row in pretraining_data.itertuples():\n",
    "    row_text = regex.sub('', row.text)\n",
    "    row_text = re.sub(regex_num, '', row_text)\n",
    "    words = row_text.split()\n",
    "    prep_text.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the new data - adding new vocabulary\n",
    "prev_model.build_vocab(prep_text, update=True)\n",
    "prev_model.train(prep_text, total_examples=prev_model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50259c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new model\n",
    "prev_model.save('./models/medical_fast_text.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9fbaff",
   "metadata": {},
   "source": [
    "# Train an LSTM model usnig the FastText embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afe026",
   "metadata": {},
   "source": [
    "## Encode the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e14c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new gensim model\n",
    "from gensim.models import FastText\n",
    "fasttext_model=FastText.load('./models/medical_fast_text.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trainign and \n",
    "train_data_final_exported,test_data_final_exported=pickle.load(open('./data/data_for_model.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data_final_exported.X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_data_final_exported.clf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bdcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad all the sequences \n",
    "X_train_final=[]\n",
    "for x in X_train:\n",
    "    new_x=x.copy()\n",
    "    while len(new_x)<11:\n",
    "        new_x.append('nan_word')\n",
    "    X_train_final.append(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the words into vectors using the fasttext model. Padding is encoded using a zero vector. \n",
    "X_train_fasttext=[]\n",
    "for x in X_train_final:\n",
    "    row=[]\n",
    "    for word in x:\n",
    "        if word=='nan_word':\n",
    "            row.append([0]*300)\n",
    "        else:\n",
    "            row.append(fasttext_model.wv[word])\n",
    "    row=np.array(row)\n",
    "    X_train_fasttext.append(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc411b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_fasttext=np.stack(X_train_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[X_train_fasttext,y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe80955",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_data, open('./data/train_fasttexyt_encoded.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256988e",
   "metadata": {},
   "source": [
    "## Train an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pickle.load(open('./data/train_fasttexyt_encoded.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242da1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow configuration for improved stabitity\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dff56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e915b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the validation cohort from the train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input,Bidirectional,Dropout,Multiply\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "callbacks = tf.keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model tensorflow architecture\n",
    "\n",
    "inputA = Input(shape=(X_train.shape[1],X_train.shape[2],))\n",
    "x = Bidirectional(LSTM(50, return_sequences=False))(inputA)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(10, activation='relu')(x)\n",
    "prefinal=Dense(5, activation='relu')(x)\n",
    "final = Dense(1, activation='sigmoid')(prefinal)\n",
    "model = tf.keras.Model(inputs=[inputA], outputs=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58daa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search for best model - tested versus the validation cohort\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Hyperparameter searched\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "optimizers = ['RMSprop', 'Adam', 'SGD']\n",
    "weight_initializations = ['random_normal', 'random_uniform', 'glorot_uniform']\n",
    "batch_sizes = [128, 256, 512]\n",
    "\n",
    "# Running a grid-search over the parameters and keeping the best model\n",
    "max_auc = 0\n",
    "counter=len(learning_rates)*len(optimizers)*len(weight_initializations)*len(batch_sizes)*3\n",
    "for i in range(3):\n",
    "    random.seed(i)\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers:\n",
    "            for weight_init in weight_initializations:\n",
    "                for batch_size in batch_sizes:\n",
    "                        opt = getattr(tf.keras.optimizers, optimizer_name)(learning_rate=lr)\n",
    "                        model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "                        epochs = 2000\n",
    "                        early_stopCB = callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "                        mcp_save = callbacks.ModelCheckpoint(f'./models/fast_text_check.hdf5', save_best_only=True,\n",
    "                                                              monitor='val_loss', mode='min')\n",
    "                        tbCB = callbacks.TensorBoard(log_dir='Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "                        hist = model.fit(x=[X_train], y=y_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         epochs=epochs,\n",
    "                                         verbose=0,\n",
    "                                         callbacks=[early_stopCB, mcp_save, tbCB],\n",
    "                                         validation_data=[X_val, y_val],\n",
    "                                         shuffle=True)\n",
    "                        model.load_weights('./models/fast_text_check.hdf5')\n",
    "                        roc_auc = roc_auc_score(y_val,model.predict(X_val))\n",
    "                        if roc_auc > max_auc:\n",
    "                            max_auc = roc_auc\n",
    "                            print(f\"Max AUC: {max_auc} | Learning Rate: {lr} | Optimizer: {optimizer_name} | Weight Initialization: {weight_init} | Batch Size: {batch_size}\")\n",
    "                            model.save_weights('./models/fast_text_best.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e60d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
